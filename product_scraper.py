import csv
from datetime import datetime
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.webdriver.chrome.options import Options
from selenium.common.exceptions import TimeoutException, NoSuchElementException
import time
import random
from urllib.parse import quote
import re
import warnings
import logging
import os

# åœ¨æ–‡ä»¶é–‹é ­æ·»åŠ é€™äº›è¡Œä¾†æŠ‘åˆ¶æ‰€æœ‰è­¦å‘Šå’Œæ—¥èªŒ
warnings.filterwarnings("ignore")
logging.getLogger('selenium').setLevel(logging.CRITICAL)
logging.getLogger('urllib3').setLevel(logging.CRITICAL)

# æŠ‘åˆ¶ Chrome ç›¸é—œçš„éŒ¯èª¤è¨Šæ¯
os.environ['WDM_LOG_LEVEL'] = '0'
os.environ['WDM_PRINT_FIRST_LINE'] = 'False'

def fetch_products_for_momo(keyword, max_products=50, progress_callback=None):
    """
    ä½¿ç”¨ Selenium å¾ momo è³¼ç‰©ç¶²æŠ“å–å•†å“è³‡è¨Š
    
    Args:
        keyword (str): æœå°‹é—œéµå­—
        max_products (int): æœ€å¤§æŠ“å–å•†å“æ•¸é‡
        progress_callback (function): é€²åº¦å›èª¿å‡½å¼ï¼Œæ¥æ”¶ (current, total, message) åƒæ•¸
    
    Returns:
        list: å•†å“è³‡è¨Šåˆ—è¡¨ï¼Œæ¯å€‹å•†å“åŒ…å« id, title, price, image_url, url, platform, sku
    """
    
    products = []
    product_id = 1  # é †åºç·¨è™Ÿ
    driver = None
    page = 1  # ç•¶å‰é æ•¸
    seen_skus = set()  # è¿½è¹¤å·²ç¶“æ”¶é›†çš„ SKUï¼Œé¿å…é‡è¤‡
    consecutive_empty_pages = 0  # é€£çºŒç©ºç™½é è¨ˆæ•¸å™¨
    
    try:
        # è¨­å®š Chrome é¸é …
        chrome_options = Options()
        chrome_options.add_argument('--headless')  # å•Ÿç”¨ç„¡é ­æ¨¡å¼ï¼ˆé›²ç«¯éƒ¨ç½²å¿…éœ€ï¼‰
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--disable-software-rasterizer')
        chrome_options.add_argument('--disable-extensions')
        chrome_options.add_argument('--disable-plugins')
        chrome_options.add_argument('--disable-background-timer-throttling')
        chrome_options.add_argument('--disable-backgrounding-occluded-windows')
        chrome_options.add_argument('--disable-renderer-backgrounding')
        chrome_options.add_argument('--disable-web-security')
        chrome_options.add_argument('--disable-features=VizDisplayCompositor')
        chrome_options.add_argument('--disable-ipc-flooding-protection')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        # ç¦ç”¨åœ–ç‰‡è¼‰å…¥ä»¥æé«˜é€Ÿåº¦
        prefs = {
            "profile.managed_default_content_settings.images": 2,
            "profile.default_content_setting_values.notifications": 2
        }
        chrome_options.add_experimental_option("prefs", prefs)
        
        # åˆå§‹åŒ– WebDriver
        driver = webdriver.Chrome(options=chrome_options)
        driver.set_page_load_timeout(30)
        print(f"æ­£åœ¨æœå°‹ momo: {keyword}")
        
        # ğŸ“Š å›å ±åˆå§‹é€²åº¦
        if progress_callback:
            progress_callback(0, max_products, f'ğŸ” æ­£åœ¨æœå°‹ MOMO: {keyword}')
        
        # ç­‰å¾…é é¢è¼‰å…¥
        wait = WebDriverWait(driver, 15)
        
        # å¤šé æŠ“å–å¾ªç’°
        while len(products) < max_products:
            # å»ºæ§‹æœå°‹ URLï¼ˆåŒ…å«é æ•¸ï¼‰
            encoded_keyword = quote(keyword)
            search_url = f"https://www.momoshop.com.tw/search/searchShop.jsp?keyword={encoded_keyword}&searchType=1&cateLevel=0&ent=k&sortType=1&curPage={page}"
            
            print(f"æ­£åœ¨æŠ“å–ç¬¬ {page} é ...")
            
            # ğŸ“Š å›å ±é é¢è¼‰å…¥é€²åº¦
            if progress_callback:
                progress_callback(len(products), max_products, f'ğŸ“„ MOMO ç¬¬ {page} é è¼‰å…¥ä¸­... (å·²æ”¶é›† {len(products)}/{max_products} ç­†)')
            
            # é é¢è¼‰å…¥é‡è©¦
            attempt = 1
            max_attempts = 3
            product_elements = []
            while attempt <= max_attempts:
                try:
                    driver.get(search_url)
                    time.sleep(3)  # ç­‰å¾…é é¢è¼‰å…¥
                    
                    # å˜—è©¦æŸ¥æ‰¾å•†å“å…ƒç´ 
                    selectors_to_try = [
                        "li.listAreaLi",
                        ".listAreaUl li.listAreaLi",
                        "li.goodsItemLi",
                        ".prdListArea .goodsItemLi",
                        ".searchPrdListArea li",
                        "li[data-gtm]",
                        ".goodsItemLi",
                        ".searchPrdList li"
                    ]
                    
                    for selector in selectors_to_try:
                        try:
                            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, selector)))
                            product_elements = driver.find_elements(By.CSS_SELECTOR, selector)
                            if product_elements:
                                #print(f"ä½¿ç”¨é¸æ“‡å™¨ '{selector}' æ‰¾åˆ° {len(product_elements)} å€‹å•†å“")
                                break
                        except TimeoutException:
                            continue
                    
                    # å¦‚æœæ‰¾åˆ°æœ‰æ•ˆå•†å“å…ƒç´ æˆ–å•†å“æ•¸é‡å°‘æ–¼ 20 å€‹ä½†å¤§æ–¼ 0ï¼Œå‰‡é€€å‡ºé‡è©¦
                    if product_elements:
                        break
                    # å¦‚æœæœªæ‰¾åˆ°å•†å“å…ƒç´ æˆ–å•†å“æ•¸é‡å°‘æ–¼ 20 å€‹ï¼Œå‰‡é‡è©¦
                    print(f"ç¬¬ {page} é æœªæ‰¾åˆ°è¶³å¤ å•†å“å…ƒç´ ï¼ˆæ‰¾åˆ° {len(product_elements)} å€‹ï¼‰ï¼Œé‡è©¦ {attempt}/{max_attempts}")
                    attempt += 1
                    time.sleep(random.uniform(3, 6))  # é‡è©¦é–“éš”
                except TimeoutException:
                    print(f"ç¬¬ {page} é è¼‰å…¥è¶…æ™‚ï¼Œé‡è©¦ {attempt}/{max_attempts}")
                    attempt += 1
                    time.sleep(random.uniform(3, 6))
            
            if not product_elements:
                print("ç„¡æ³•æ‰¾åˆ°å•†å“å…ƒç´ ï¼Œå¯èƒ½é é¢çµæ§‹å·²æ”¹è®Šæˆ–å·²åˆ°é”æœ€å¾Œä¸€é ")
                break
            
            print(f"é–‹å§‹è§£æ {len(product_elements)} å€‹å•†å“")
            page_products_count = 0
            
            # è§£ææ¯å€‹å•†å“
            for i, element in enumerate(product_elements):
                try:
                    # å¦‚æœå·²ç¶“ç²å¾—è¶³å¤ çš„å•†å“ï¼Œå°±åœæ­¢
                    if len(products) >= max_products:
                        break
                    
                    # æå–å•†å“æ¨™é¡Œ
                    title = ""
                    title_selectors = [
                        "h3.prdName",
                        ".prdNameTitle h3.prdName",
                        ".prdName",
                        "h3",
                        "a[title]",
                        "img[alt]",
                        ".goodsName",
                        ".goodsInfo h3",
                        "a"
                    ]
                    
                    for selector in title_selectors:
                        try:
                            title_elem = element.find_element(By.CSS_SELECTOR, selector)
                            if selector == "img[alt]":
                                title = title_elem.get_attribute("alt").strip()
                            elif selector == "a[title]":
                                title = title_elem.get_attribute("title").strip()
                            else:
                                title = title_elem.text.strip()
                            
                            if title and len(title) > 5:  # ç¢ºä¿æ¨™é¡Œæœ‰è¶³å¤ é•·åº¦
                                break
                        except NoSuchElementException:
                            continue
                    
                    # å¦‚æœæ²’æœ‰æ‰¾åˆ°æ¨™é¡Œï¼Œè·³éé€™å€‹å•†å“
                    if not title:
                        continue
                    
                    # æå–åƒ¹æ ¼ï¼ˆå…ˆç”¨å¤šç¨®é¸æ“‡å™¨ï¼Œè‹¥å¤±æ•—å‰‡ç”¨æ•´å€‹å…ƒç´ çš„æ–‡å­—åšå›é€€ï¼‰
                    price = 0
                    price_selectors = [
                        ".money .price b",
                        ".price b",
                        ".money b",
                        ".price",
                        ".money",
                        ".cost",
                        "b",
                        "strong",
                        ".goodsPrice",
                        ".priceInfo",
                        ".prodPrice",
                        ".prdPrice"
                    ]

                    for selector in price_selectors:
                        try:
                            price_elements = element.find_elements(By.CSS_SELECTOR, selector)
                            for price_elem in price_elements:
                                price_text = price_elem.text
                                if price_text and any(c.isdigit() for c in price_text):
                                    # æå–æ•¸å­—
                                    numbers = re.findall(r'\d+', price_text.replace(',', ''))
                                    if numbers:
                                        # å–æœ€å¤§çš„æ•¸å­—ä½œç‚ºåƒ¹æ ¼ï¼ˆé¿å…å–åˆ°æŠ˜æ‰£ç™¾åˆ†æ¯”ç­‰å°æ•¸å­—ï¼‰
                                        potential_prices = [int(num) for num in numbers if int(num) > 10]
                                        if potential_prices:
                                            price = max(potential_prices)
                                            break
                            if price > 0:
                                break
                        except NoSuchElementException:
                            continue

                    # å›é€€ç­–ç•¥ï¼šç”¨æ•´å€‹å…ƒç´ çš„æ–‡æœ¬æŠ“å–æ•¸å­—ï¼ˆå¦‚æœå…ˆå‰æ²’æŠ“åˆ°åƒ¹æ ¼ï¼‰
                    if price <= 0:
                        try:
                            full_text = element.text
                            numbers = re.findall(r'\d+', full_text.replace(',', ''))
                            if numbers:
                                potential_prices = [int(num) for num in numbers if int(num) > 10]
                                if potential_prices:
                                    price = max(potential_prices)
                        except Exception:
                            price = 0

                    # å¦‚æœé‚„æ²’æœ‰æ‰¾åˆ°åƒ¹æ ¼ï¼Œå°±è·³éé€™å€‹å•†å“
                    if price <= 0:
                        continue
                    
                    # æå–å•†å“é€£çµ
                    url = ""
                    try:
                        link_elem = element.find_element(By.CSS_SELECTOR, "a.goods-img-url")
                        url = link_elem.get_attribute("href")
                        if not url.startswith("http"):
                            url = "https://www.momoshop.com.tw" + url
                    except NoSuchElementException:
                        # å˜—è©¦æ‰¾å…¶ä»–å¯èƒ½çš„é€£çµé¸æ“‡å™¨
                        try:
                            link_elem = element.find_element(By.CSS_SELECTOR, "a[href*='/goods/']")
                            url = link_elem.get_attribute("href")
                            if not url.startswith("http"):
                                url = "https://www.momoshop.com.tw" + url
                        except NoSuchElementException:
                            # å˜—è©¦æ‰¾ä»»ä½•é€£çµ
                            try:
                                link_elem = element.find_element(By.CSS_SELECTOR, "a[href]")
                                url = link_elem.get_attribute("href")
                                if url and not url.startswith("http"):
                                    url = "https://www.momoshop.com.tw" + url
                            except NoSuchElementException:
                                url = ""
                    
                    # å˜—è©¦å¾éš±è— input å–å¾—å•†å“ id ä½œç‚º skuï¼ˆmomo çš„ list ä¸­å¸¸è¦‹ï¼‰
                    sku = ""
                    try:
                        input_elem = element.find_element(By.CSS_SELECTOR, "input#viewProdId")
                        sku_val = input_elem.get_attribute("value")
                        if sku_val:
                            sku = sku_val
                    except NoSuchElementException:
                        sku = ""

                    # è‹¥ä»ç„¡ skuï¼Œå˜—è©¦å¾ url æå– i_code æˆ–æœ€å¾Œä¸€æ®µ
                    if not sku and url:
                        match = re.search(r'i_code=(\d+)', url)
                        if match:
                            sku = match.group(1)
                        else:
                            url_parts = url.rstrip('/').split('/')
                            if url_parts:
                                last_part = url_parts[-1]
                                if '?' in last_part:
                                    last_part = last_part.split('?')[0]
                                if '.' in last_part:
                                    last_part = last_part.split('.')[0]
                                sku = last_part
                    # å¦‚æœæœ‰ sku ä½†æ²’æœ‰ urlï¼Œå¯ä»¥ç”¨ momo çš„å•†å“é æ¨£å¼çµ„æˆ url
                    if not url and sku:
                        url = f"https://www.momoshop.com.tw/goods/GoodsDetail.jsp?i_code={sku}"
                    
                    # æå–å•†å“åœ–ç‰‡
                    image_url = ""
                    try:
                        # å„ªå…ˆå°‹æ‰¾ç¬¬ä¸€å€‹å•†å“åœ–ç‰‡
                        img_elem = element.find_element(By.CSS_SELECTOR, "img.prdImg")
                        # å„ªå…ˆä½¿ç”¨ srcï¼Œç„¶å¾Œæ˜¯ data-originalï¼Œæœ€å¾Œæ˜¯ data-src
                        image_url = (img_elem.get_attribute("src") or 
                                   img_elem.get_attribute("data-original") or 
                                   img_elem.get_attribute("data-src"))
                        
                        if image_url:
                            # è™•ç†ç›¸å°è·¯å¾‘å’Œå”è­°ç›¸å°è·¯å¾‘
                            if image_url.startswith("//"):
                                image_url = "https:" + image_url
                            elif image_url.startswith("/"):
                                image_url = "https://www.momoshop.com.tw" + image_url
                            elif not image_url.startswith("http"):
                                # å¦‚æœæ˜¯ç›¸å°è·¯å¾‘ä½†ä¸ä»¥ / é–‹é ­ï¼Œå‡è¨­æ˜¯ momoshop çš„åœ–ç‰‡
                                if "momoshop" not in image_url:
                                    image_url = "https://cdn3.momoshop.com.tw/momoshop/upload/media/" + image_url
                                else:
                                    image_url = "https://" + image_url
                    except NoSuchElementException:
                        # å¦‚æœæ‰¾ä¸åˆ° prdImgï¼Œå˜—è©¦å…¶ä»–åœ–ç‰‡é¸æ“‡å™¨
                        try:
                            img_elem = element.find_element(By.CSS_SELECTOR, "img")
                            image_url = (img_elem.get_attribute("src") or 
                                       img_elem.get_attribute("data-original") or 
                                       img_elem.get_attribute("data-src"))
                            
                            if image_url:
                                # è™•ç†ç›¸å°è·¯å¾‘å’Œå”è­°ç›¸å°è·¯å¾‘
                                if image_url.startswith("//"):
                                    image_url = "https:" + image_url
                                elif image_url.startswith("/"):
                                    image_url = "https://www.momoshop.com.tw" + image_url
                                elif not image_url.startswith("http"):
                                    if "momoshop" not in image_url:
                                        image_url = "https://cdn3.momoshop.com.tw/momoshop/upload/media/" + image_url
                                    else:
                                        image_url = "https://" + image_url
                        except NoSuchElementException:
                            image_url = ""
                    
                    # ç¢ºä¿æ‰€æœ‰å¿…è¦æ¬„ä½éƒ½æœ‰å€¼æ‰åŠ å…¥å•†å“
                    if title and price > 0 and url:
                        # æª¢æŸ¥ SKU æ˜¯å¦é‡è¤‡
                        if sku and sku in seen_skus:
                            #print(f"è·³éé‡è¤‡ SKU: {sku}")
                            continue
                        
                        product = {
                            "id": product_id,
                            "title": title,
                            "price": price,
                            "image_url": image_url if image_url else "",
                            "url": url,
                            "platform": "momo",
                            "sku": sku
                        }
                        products.append(product)
                        if sku:
                            seen_skus.add(sku)
                        product_id += 1
                        page_products_count += 1
                        
                        # ğŸ“Š å›å ±å³æ™‚é€²åº¦ï¼ˆæ¯æŠ“åˆ°ä¸€å€‹å•†å“å°±æ›´æ–°ï¼‰
                        if progress_callback:
                            progress_callback(
                                len(products), 
                                max_products, 
                                f'ğŸ“¦ MOMO: å·²æ”¶é›† {len(products)}/{max_products} ç­†å•†å“'
                            )
                        
                        #print(f"æˆåŠŸè§£æå•†å“ {len(products)}: {title[:50]}... (NT$ {price:,})")
                    
                    # é¿å…éæ–¼é »ç¹çš„æ“ä½œ
                    time.sleep(random.uniform(0.05, 0.1))
                    
                except Exception as e:
                    print(f"è§£æç¬¬ {i+1} å€‹å•†å“æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                    continue
            
            print(f"ç¬¬ {page} é æ‰¾åˆ° {len(product_elements)} å€‹å•†å“å…ƒç´ ï¼ŒæˆåŠŸè§£æ {page_products_count} å€‹æœ‰æ•ˆå•†å“ï¼Œç›®å‰ç¸½è¨ˆ {len(products)} å€‹å•†å“")
            
            # ğŸ”§ æ”¹é€²ï¼šåªæœ‰åœ¨ã€Œå·²é”åˆ°ç›®æ¨™æ•¸é‡ã€æˆ–ã€Œé€£çºŒå¤šé éƒ½æ²’æœ‰å•†å“ã€æ™‚æ‰åœæ­¢
            # ç§»é™¤ã€Œå•†å“æ•¸é‡å°‘æ–¼ 20 å°±åœæ­¢ã€çš„é™åˆ¶ï¼Œå› ç‚ºæœ‰äº›é—œéµå­—æœ¬ä¾†å•†å“å°±å°‘
            
            # å¦‚æœé€™ä¸€é æ²’æœ‰æ‰¾åˆ°ä»»ä½•æœ‰æ•ˆå•†å“ï¼Œæª¢æŸ¥æ˜¯å¦è¦ç¹¼çºŒ
            if page_products_count == 0:
                consecutive_empty_pages += 1
                print(f"âš ï¸ ç¬¬ {page} é æ²’æœ‰æ‰¾åˆ°æœ‰æ•ˆå•†å“ï¼ˆé€£çºŒ {consecutive_empty_pages} é ç‚ºç©ºï¼‰")
                
                # ğŸ†• åªæœ‰åœ¨é é¢å•†å“å…ƒç´ ä¹Ÿå¾ˆå°‘æ™‚æ‰åœæ­¢ï¼ˆçœŸçš„æ²’å•†å“äº†ï¼‰
                if len(product_elements) < 5:
                    print("å•†å“å…ƒç´ ä¹Ÿå¾ˆå°‘ï¼Œåˆ¤å®šç‚ºçœŸæ­£çš„æœ€å¾Œä¸€é ï¼Œåœæ­¢æŠ“å–")
                    break
                # å¦‚æœé€£çºŒ3é éƒ½æ²’æœ‰æœ‰æ•ˆå•†å“ï¼Œä¹Ÿåœæ­¢ï¼ˆé¿å…ç„¡é™å¾ªç’°ï¼‰
                elif consecutive_empty_pages >= 3:
                    print(f"é€£çºŒ {consecutive_empty_pages} é éƒ½æ²’æœ‰æœ‰æ•ˆå•†å“ï¼Œåœæ­¢æŠ“å–")
                    break
                else:
                    print(f"ä½†é é¢é‚„æœ‰å•†å“å…ƒç´ ï¼Œå¯èƒ½åªæ˜¯è¢«éæ¿¾æ‰ï¼ˆä¾‹å¦‚é‡è¤‡SKUï¼‰ï¼Œç¹¼çºŒå˜—è©¦ä¸‹ä¸€é ")
                    # é™„åŠ åµéŒ¯è¼¸å‡ºï¼šå°å‡ºå‰ 3 å€‹å•†å“å…ƒç´ çš„ outerHTMLï¼Œå¹«åŠ©åˆ†æç‚ºä½•ç„¡æ³•è§£æ
                    try:
                        print("--- MOMO sample product_elements outerHTML (first 3) ---")
                        for idx, pe in enumerate(product_elements[:3]):
                            try:
                                outer = pe.get_attribute('outerHTML')
                            except Exception:
                                outer = '<unable to get outerHTML>'
                            print(f"--- element #{idx+1} ---")
                            # å°è¼ƒå¤šå­—æ•¸ä»¥ä¾¿æ‰¾åˆ°åƒ¹æ ¼è³‡è¨Š
                            print(outer[:4000])
                            try:
                                text_snip = pe.text
                            except Exception:
                                text_snip = '<unable to get text>'
                            print("element.text:\n", text_snip[:1000])
                        print("--- end sample ---")
                    except Exception as e:
                        print(f"åˆ—å° sample outerHTML æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            else:
                # é‡ç½®é€£çºŒç©ºç™½é è¨ˆæ•¸å™¨
                consecutive_empty_pages = 0
                    # ç¹¼çºŒåˆ°ä¸‹ä¸€é å˜—è©¦
                
            # å¦‚æœé‚„éœ€è¦æ›´å¤šå•†å“ï¼Œå‰‡è·³åˆ°ä¸‹ä¸€é 
            if len(products) < max_products:
                page += 1
                print(f"ğŸ“„ æº–å‚™æŠ“å–ç¬¬ {page} é ...")
                time.sleep(random.uniform(2, 3))  # é é¢é–“éš”
            else:
                print(f"âœ… å·²é”åˆ°ç›®æ¨™æ•¸é‡ {max_products} ç­†ï¼Œåœæ­¢æŠ“å–")
                break
        
        print(f"æˆåŠŸå¾ momo ç²å– {len(products)} å€‹å”¯ä¸€å•†å“ï¼ˆå·²è‡ªå‹•éæ¿¾é‡è¤‡ SKUï¼‰")
        
        # ğŸ“Š å›å ±å®Œæˆé€²åº¦
        if progress_callback:
            progress_callback(len(products), max_products, f'âœ… MOMO å®Œæˆï¼å…±æ”¶é›† {len(products)} ç­†å•†å“')
        
        return products
        
    except Exception as e:
        print(f"momo Selenium çˆ¬èŸ²ç™¼ç”ŸéŒ¯èª¤: {e}")
        return []
    
    finally:
        # ç¢ºä¿é—œé–‰ç€è¦½å™¨
        if driver:
            try:
                driver.quit()
            except:
                pass


def fetch_products_for_pchome(keyword, max_products=50, progress_callback=None):
    """
    ä½¿ç”¨ Selenium å¾ PChome è³¼ç‰©ç¶²æŠ“å–å•†å“è³‡è¨Šï¼Œé©æ‡‰ 2025å¹´10æœˆ çš„æ–°ç‰ˆç¶²é çµæ§‹ã€‚
    
    Args:
        keyword (str): æœå°‹é—œéµå­—
        max_products (int): æœ€å¤§æŠ“å–å•†å“æ•¸é‡
        progress_callback (function): é€²åº¦å›èª¿å‡½å¼ï¼Œæ¥æ”¶ (current, total, message) åƒæ•¸
    
    Returns:
        list: å•†å“è³‡è¨Šåˆ—è¡¨
    """
    products = []
    product_id = 1
    driver = None
    page = 1
    seen_skus = set()
    consecutive_empty_pages = 0  # é€£çºŒç©ºç™½é è¨ˆæ•¸å™¨

    try:
        chrome_options = Options()
        chrome_options.add_argument('--headless')  # å•Ÿç”¨ç„¡é ­æ¨¡å¼ï¼ˆé›²ç«¯éƒ¨ç½²å¿…éœ€ï¼‰
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--window-size=1920,1080')
        chrome_options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36')
        
        prefs = {"profile.default_content_setting_values.notifications": 2}
        chrome_options.add_experimental_option("prefs", prefs)
        
        driver = webdriver.Chrome(options=chrome_options)
        driver.set_page_load_timeout(40)
        wait = WebDriverWait(driver, 20)
        print(f"æ­£åœ¨æœå°‹ PChome: {keyword}")
        
        # ğŸ“Š å›å ±åˆå§‹é€²åº¦
        if progress_callback:
            progress_callback(0, max_products, f'ğŸ” æ­£åœ¨æœå°‹ PChome: {keyword}')

        encoded_keyword = quote(keyword)
        search_url = f"https://24h.pchome.com.tw/search/?q={encoded_keyword}"
        driver.get(search_url)
        time.sleep(2)

        while len(products) < max_products:
            print(f"æ­£åœ¨æŠ“å– PChome ç¬¬ {page} é ...")
            
            # ğŸ“Š å›å ±é é¢è¼‰å…¥é€²åº¦
            if progress_callback:
                progress_callback(len(products), max_products, f'ğŸ“„ PChome ç¬¬ {page} é è¼‰å…¥ä¸­... (å·²æ”¶é›† {len(products)}/{max_products} ç­†)')
            
            try:
                # ç­‰å¾…æ–°çµæ§‹çš„å•†å“é …ç›®å‡ºç¾
                wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "li.c-listInfoGrid__item--gridCardGray5")))
                
                # æ»¾å‹•é é¢ä»¥ç¢ºä¿æ‰€æœ‰å•†å“éƒ½è¼‰å…¥
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(2)
                
                # æ ¹æ“šæ–°çµæ§‹ç²å–æ‰€æœ‰å•†å“å…ƒç´ 
                product_elements = driver.find_elements(By.CSS_SELECTOR, "li.c-listInfoGrid__item--gridCardGray5")
            except TimeoutException:
                print("é é¢åŠ è¼‰è¶…æ™‚æˆ–æ‰¾ä¸åˆ°æ–°çµæ§‹çš„å•†å“å®¹å™¨ (li.c-listInfoGrid__item--gridCardGray5)ã€‚")
                try:
                    driver.save_screenshot("pchome_error_screenshot.png")
                    print("å·²å„²å­˜éŒ¯èª¤æˆªåœ–: pchome_error_screenshot.png")
                except Exception as e:
                    print(f"å„²å­˜æˆªåœ–å¤±æ•—: {e}")
                break

            print(f"ç¬¬ {page} é æ‰¾åˆ° {len(product_elements)} å€‹å•†å“å…ƒç´ ")
            
            # è¨˜éŒ„é€™ä¸€é æˆåŠŸè§£æçš„å•†å“æ•¸
            page_products_count = 0

            for element in product_elements:
                if len(products) >= max_products:
                    break

                try:
                    # æå–é€£çµå’Œ SKU
                    link_element = element.find_element(By.CSS_SELECTOR, "a.c-prodInfoV2__link")
                    url = link_element.get_attribute("href")
                    if not url.startswith("https://"):
                        url = "https://24h.pchome.com.tw" + url
                    
                    sku_match = re.search(r'/prod/(.*?)(?:\?|$)', url)
                    sku = sku_match.group(1) if sku_match else ""

                    # æå–æ¨™é¡Œ
                    title_elem = element.find_element(By.CSS_SELECTOR, "div.c-prodInfoV2__title")
                    title = title_elem.text.strip()

                    # æå–åƒ¹æ ¼ï¼šå„ªå…ˆæŠ“å–ä¿ƒéŠ·åƒ¹æ ¼ï¼Œå¦‚æœæ²’æœ‰å‰‡æŠ“å–ç¶²è·¯åƒ¹
                    price = 0
                    price_found_by = None  # ç”¨æ–¼èª¿è©¦
                    
                    # æ–°ç­–ç•¥ï¼šæŠ“å–æ•´å€‹å•†å“å¡ç‰‡çš„ HTMLï¼Œç„¶å¾Œåˆ†ææ‰€æœ‰åƒ¹æ ¼
                    try:
                        # ç²å–æ•´å€‹åƒ¹æ ¼å€åŸŸçš„æ‰€æœ‰æ–‡å­—
                        price_container = element.find_element(By.CSS_SELECTOR, "div.c-prodInfoV2__body")
                        full_html = price_container.get_attribute('innerHTML')
                        
                        # ä½¿ç”¨æ­£å‰‡è¡¨é”å¼æ‰¾å‡ºæ‰€æœ‰åƒ¹æ ¼æ•¸å­—
                        # å°‹æ‰¾æ ¼å¼å¦‚ $7,999 æˆ– $10,900 çš„åƒ¹æ ¼
                        price_matches = re.findall(r'\$\s*([\d,]+)', full_html)
                        
                        if price_matches:
                            # è½‰æ›æ‰€æœ‰æ‰¾åˆ°çš„åƒ¹æ ¼ç‚ºæ•´æ•¸
                            all_prices = []
                            for match in price_matches:
                                try:
                                    price_val = int(match.replace(',', ''))
                                    if price_val > 10:  # éæ¿¾æ‰ä¸åˆç†çš„å°æ•¸å­—
                                        all_prices.append(price_val)
                                except:
                                    continue
                            
                            if all_prices:
                                # å–æœ€å°çš„åƒ¹æ ¼ï¼ˆé€šå¸¸å„ªæƒ åƒ¹æœƒæ¯”åŸåƒ¹å°ï¼‰
                                price = min(all_prices)
                                price_found_by = f"å¾ HTML æ‰¾åˆ° {len(all_prices)} å€‹åƒ¹æ ¼ï¼Œé¸æ“‡æœ€ä½: {all_prices}"
                    except:
                        pass
                    
                    # å‚™ç”¨ç­–ç•¥ï¼šå¦‚æœä¸Šé¢çš„æ–¹æ³•å¤±æ•—ï¼Œä½¿ç”¨å‚³çµ±é¸æ“‡å™¨
                    if price == 0:
                        price_selectors = [
                            "div[class*='o-prodPrice__price']",
                            "div.o-prodPrice__originalPrice",
                            "div.c-prodInfoV2__salePrice"
                        ]
                        
                        for selector in price_selectors:
                            try:
                                price_elem = element.find_element(By.CSS_SELECTOR, selector)
                                price_text = price_elem.text.strip()
                                if price_text and any(c.isdigit() for c in price_text):
                                    extracted_price = int(re.sub(r'[^\d]', '', price_text))
                                    if extracted_price > 0:
                                        price = extracted_price
                                        price_found_by = f"å‚™ç”¨é¸æ“‡å™¨: {selector}"
                                        break
                            except NoSuchElementException:
                                continue
                    
                    # èª¿è©¦è¼¸å‡º
                    if price_found_by and page == 1 and len(products) < 5:
                        print(f"  [{len(products)+1}] {title[:40]}... -> NT$ {price:,}")
                        print(f"      ä¾†æº: {price_found_by}")

                    # æå–åœ–ç‰‡
                    image_url = ""
                    try:
                        img_elem = element.find_element(By.CSS_SELECTOR, "div.c-prodInfoV2__head img")
                        image_url = img_elem.get_attribute("src")
                    except NoSuchElementException:
                        image_url = "" # æ‰¾ä¸åˆ°åœ–ç‰‡å°±ç®—äº†

                    if title and price > 0 and url and sku:
                        if sku in seen_skus:
                            continue
                        
                        seen_skus.add(sku)
                        product = {
                            "id": product_id,
                            "title": title,
                            "price": price,
                            "image_url": image_url,
                            "url": url,
                            "platform": "pchome",
                            "sku": sku
                        }
                        products.append(product)
                        product_id += 1
                        page_products_count += 1  # è¨˜éŒ„é€™ä¸€é æˆåŠŸè§£æçš„å•†å“æ•¸
                        
                        # ğŸ“Š å›å ±å³æ™‚é€²åº¦ï¼ˆæ¯æŠ“åˆ°ä¸€å€‹å•†å“å°±æ›´æ–°ï¼‰
                        if progress_callback:
                            progress_callback(
                                len(products), 
                                max_products, 
                                f'ğŸ“¦ PChome: å·²æ”¶é›† {len(products)}/{max_products} ç­†å•†å“'
                            )

                except (NoSuchElementException, ValueError) as e:
                    continue
            
            print(f"ç¬¬ {page} é æ‰¾åˆ° {len(product_elements)} å€‹å•†å“å…ƒç´ ï¼ŒæˆåŠŸè§£æ {page_products_count} å€‹æœ‰æ•ˆå•†å“ï¼Œç›®å‰ç¸½è¨ˆ {len(products)} å€‹å•†å“")
            
            # ğŸ”§ æ”¹é€²ï¼šæ™ºæ…§åœæ­¢åˆ¤æ–·
            if page_products_count == 0:
                consecutive_empty_pages += 1
                print(f"âš ï¸ ç¬¬ {page} é æ²’æœ‰æ‰¾åˆ°æœ‰æ•ˆå•†å“ï¼ˆé€£çºŒ {consecutive_empty_pages} é ç‚ºç©ºï¼‰")
                
                # åªæœ‰åœ¨é é¢å•†å“å…ƒç´ ä¹Ÿå¾ˆå°‘æ™‚æ‰åœæ­¢ï¼ˆçœŸçš„æ²’å•†å“äº†ï¼‰
                if len(product_elements) < 5:
                    print("å•†å“å…ƒç´ ä¹Ÿå¾ˆå°‘ï¼Œåˆ¤å®šç‚ºçœŸæ­£çš„æœ€å¾Œä¸€é ï¼Œåœæ­¢æŠ“å–")
                    break
                # å¦‚æœé€£çºŒ3é éƒ½æ²’æœ‰æœ‰æ•ˆå•†å“ï¼Œä¹Ÿåœæ­¢ï¼ˆé¿å…ç„¡é™å¾ªç’°ï¼‰
                elif consecutive_empty_pages >= 3:
                    print(f"é€£çºŒ {consecutive_empty_pages} é éƒ½æ²’æœ‰æœ‰æ•ˆå•†å“ï¼Œåœæ­¢æŠ“å–")
                    break
                else:
                    print(f"ä½†é é¢é‚„æœ‰å•†å“å…ƒç´ ï¼Œå¯èƒ½åªæ˜¯è¢«éæ¿¾æ‰ï¼ˆä¾‹å¦‚é‡è¤‡SKUï¼‰ï¼Œç¹¼çºŒå˜—è©¦ä¸‹ä¸€é ")
            else:
                # é‡ç½®é€£çºŒç©ºç™½é è¨ˆæ•¸å™¨
                consecutive_empty_pages = 0
            
            # å¦‚æœå·²é”åˆ°ç›®æ¨™æ•¸é‡å°±åœæ­¢
            if len(products) >= max_products:
                print(f"âœ… å·²é”åˆ°ç›®æ¨™æ•¸é‡ {max_products} ç­†ï¼Œåœæ­¢æŠ“å–")
                break

            # é»æ“Šä¸‹ä¸€é æŒ‰éˆ•
            try:
                # å…ˆæ»¾å‹•åˆ°é é¢åº•éƒ¨ï¼Œç¢ºä¿ä¸‹ä¸€é æŒ‰éˆ•å¯è¦‹
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(1)
                
                # ä½¿ç”¨æ–°çš„é¸æ“‡å™¨ä¾†æ‰¾åˆ°ä¸‹ä¸€é æŒ‰éˆ•
                # æ ¹æ“š HTML çµæ§‹ï¼Œå°‹æ‰¾åŒ…å«å‘å³ç®­é ­åœ–ç¤ºçš„å…ƒç´ 
                next_icon = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, "i.o-iconFonts--arrowSolidRight")))
                # é»æ“Šåœ–ç¤ºçš„çˆ¶å…ƒç´ ï¼ˆæ‡‰è©²æ˜¯å¯é»æ“Šçš„æŒ‰éˆ•ï¼‰
                next_page_button = next_icon.find_element(By.XPATH, "..")
                driver.execute_script("arguments[0].click();", next_page_button)
                page += 1
                time.sleep(random.uniform(3, 5))
            except (TimeoutException, NoSuchElementException):
                print("æ‰¾ä¸åˆ°ä¸‹ä¸€é æŒ‰éˆ•ï¼ŒæŠ“å–çµæŸã€‚")
                break
        
        print(f"æˆåŠŸå¾ PChome ç²å– {len(products)} å€‹å”¯ä¸€å•†å“ã€‚")
        
        # ğŸ“Š å›å ±å®Œæˆé€²åº¦
        if progress_callback:
            progress_callback(len(products), max_products, f'âœ… PChome å®Œæˆï¼å…±æ”¶é›† {len(products)} ç­†å•†å“')
        
        return products

    except Exception as e:
        print(f"PChome Selenium çˆ¬èŸ²ç™¼ç”ŸéŒ¯èª¤: {e}")
        return []

    finally:
        if driver:
            try:
                driver.quit()
            except:
                pass


def save_to_csv(products, filename, query_keyword, append_mode=True):
    """
    å°‡å•†å“è³‡è¨Šå„²å­˜ç‚ºCSVæ ¼å¼
    
    Args:
        products (list): å•†å“è³‡è¨Šåˆ—è¡¨
        filename (str): CSVæª”æ¡ˆåç¨±
        query_keyword (str): æŸ¥è©¢é—œéµå­—
        append_mode (bool): True=è¿½åŠ æ¨¡å¼ï¼ŒFalse=è¦†è“‹æ¨¡å¼
    """
    if not products:
        print(f"æ²’æœ‰å•†å“è³‡æ–™å¯ä»¥å„²å­˜åˆ° {filename}")
        return
    
    # CSVæ¬„ä½å®šç¾©ï¼ˆèˆ‡ä½ çš„CSVæ ¼å¼ä¸€è‡´ï¼‰
    fieldnames = [
        'id', 'sku', 'title', 'image', 'url', 'platform', 
        'connect', 'price', 'uncertainty_problem', 'query', 
        'annotator', 'created_at', 'updated_at'
    ]
    
    # ç•¶å‰æ™‚é–“
    current_time = datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]
    
    # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨ï¼Œä»¥åŠæ˜¯å¦éœ€è¦è¿½åŠ 
    file_exists = os.path.exists(filename)
    
    # å¦‚æœæ˜¯è¿½åŠ æ¨¡å¼ä¸”æª”æ¡ˆå­˜åœ¨ï¼Œéœ€è¦å…ˆè®€å–ç¾æœ‰çš„æœ€å¤§ id
    start_id = 1
    if append_mode and file_exists:
        try:
            import pandas as pd
            existing_df = pd.read_csv(filename)
            if not existing_df.empty and 'id' in existing_df.columns:
                start_id = existing_df['id'].max() + 1
        except Exception as e:
            print(f"è®€å–ç¾æœ‰æª”æ¡ˆå¤±æ•—ï¼Œå°‡å¾ id=1 é–‹å§‹: {e}")
            start_id = 1
    
    # æ±ºå®šé–‹å•Ÿæ¨¡å¼ï¼šè¿½åŠ æˆ–è¦†è“‹
    mode = 'a' if (append_mode and file_exists) else 'w'
    
    with open(filename, mode, newline='', encoding='utf-8') as csvfile:
        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
        
        # åªæœ‰åœ¨æ–°å»ºæª”æ¡ˆæˆ–è¦†è“‹æ¨¡å¼æ™‚æ‰å¯«å…¥è¡¨é ­
        if mode == 'w':
            writer.writeheader()
        
        for i, product in enumerate(products):
            # æ§‹å»ºCSVè¡Œè³‡æ–™ï¼ˆåŒ¹é…ä½ çš„æ ¼å¼ï¼‰
            row = {
                'id': start_id + i,  # ä½¿ç”¨é€£çºŒçš„ id
                'sku': product['sku'],
                'title': product['title'],
                'image': product['image_url'],
                'url': product['url'],
                'platform': product['platform'],
                'connect': '',  # ç©ºå€¼ï¼Œå¦‚æœéœ€è¦å¯ä»¥å¾ŒçºŒå¡«å…¥
                'price': f"{product['price']:.2f}",
                'uncertainty_problem': '0',
                'query': query_keyword,
                'annotator': 'model_prediction',
                'created_at': current_time,
                'updated_at': current_time
            }
            writer.writerow(row)
    
    print(f"âœ… æˆåŠŸå„²å­˜ {len(products)} ç­†å•†å“è‡³ {filename}")


if __name__ == "__main__":
    # æ¸¬è©¦çˆ¬èŸ²
    keyword = input("è¼¸å…¥é—œéµå­—: ")
    english_keyword = input("è¼¸å…¥é—œéµå­—çš„è‹±æ–‡åç¨±: ")
    num = int(input("è¼¸å…¥æ•¸é‡: "))
    
    # æŠ“å– MOMO å•†å“
    print("\n=== é–‹å§‹æŠ“å– MOMO å•†å“ ===")
    momo_products = fetch_products_for_momo(keyword, num)
    
    # å„²å­˜ MOMO å•†å“è‡³ CSV æª”æ¡ˆ
    save_to_csv(momo_products, "momo.csv", english_keyword)

    if momo_products:
        print(f"\næ‰¾åˆ° {len(momo_products)} å€‹ MOMO å•†å“ï¼š")
        for product in momo_products[:5]:  # åªé¡¯ç¤ºå‰5å€‹
            print(f"ID: {product['id']}")
            print(f"æ¨™é¡Œ: {product['title']}")
            print(f"åƒ¹æ ¼: NT$ {product['price']:,}")
            print(f"åœ–ç‰‡: {product['image_url']}")
            print(f"é€£çµ: {product['url']}")
            print(f"å¹³å°: {product['platform']}")
            print("-" * 50)
        if len(momo_products) > 5:
            print(f"... ä»¥åŠå…¶ä»– {len(momo_products) - 5} å€‹å•†å“")
    else:
        print("æ²’æœ‰æ‰¾åˆ° MOMO å•†å“")

    # æŠ“å– PChome å•†å“
    print("\n=== é–‹å§‹æŠ“å– PChome å•†å“ ===")
    pchome_products = fetch_products_for_pchome(keyword, num)
    
    # å„²å­˜ PChome å•†å“è‡³ CSV æª”æ¡ˆ
    save_to_csv(pchome_products, "pchome.csv", english_keyword)

    if pchome_products:
        print(f"\næ‰¾åˆ° {len(pchome_products)} å€‹ PChome å•†å“ï¼š")
        for product in pchome_products[:5]:  # åªé¡¯ç¤ºå‰5å€‹
            print(f"ID: {product['id']}")
            print(f"æ¨™é¡Œ: {product['title']}")
            print(f"åƒ¹æ ¼: NT$ {product['price']:,}")
            print(f"åœ–ç‰‡: {product['image_url']}")
            print(f"é€£çµ: {product['url']}")
            print(f"å¹³å°: {product['platform']}")
            print("-" * 50)
        if len(pchome_products) > 5:
            print(f"... ä»¥åŠå…¶ä»– {len(pchome_products) - 5} å€‹å•†å“")
    else:
        print("æ²’æœ‰æ‰¾åˆ° PChome å•†å“")
    
    print(f"\n=== å®Œæˆï¼===")
    print(f"MOMO å•†å“å·²å„²å­˜è‡³: momo.csv")
    print(f"PChome å•†å“å·²å„²å­˜è‡³: pchome.csv")